#!/usr/bin/env python3
"""
PentestGPT with Gemini Integration - Enhanced Version
Advanced penetration testing agent using Google Gemini for superior reasoning
Replaces GPT-4 usage with Gemini-only implementation
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import os

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from loguru import logger
import yaml

from core.shared_utils import ConfigManager, LoggerManager, DirectoryManager, GeminiClient

class PentestGPTGemini:
    """Enhanced PentestGPT using only Gemini for all AI reasoning"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        LoggerManager.setup_logger('pentestgpt_gemini')
        
        # Use shared Gemini client
        self.gemini_client = GeminiClient()
        
        # Gemini configuration - NO GPT-4 usage
        self.api_key = os.getenv('GEMINI_API_KEY') or self.config.get('gemini', {}).get('api_key')
        self.model_name = "gemini-1.5-flash"  # Updated to current model
        
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY required - no GPT-4 fallback")
        
        # Configure Gemini with unrestricted safety settings for cybersecurity
        genai.configure(api_key=self.api_key)
        
        self.safety_settings = {
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
        
        self.model = genai.GenerativeModel(
            model_name=self.model_name,
            safety_settings=self.safety_settings
        )
        
        # Session management
        self.current_session = None
        self.session_history = []
        
        # Setup directories
        DirectoryManager.ensure_directory("data/pentest_sessions")
        DirectoryManager.ensure_directory("data/pentest_analysis")
        DirectoryManager.ensure_directory("data/pentest_reports")
        
        self.sessions_dir = Path("data/pentest_sessions")
        self.analysis_dir = Path("data/pentest_analysis")
        self.reports_dir = Path("data/pentest_reports")
        
        # Set client type for conditional logic
        self.client_type = "gemini"
        
        logger.info("ðŸ›¡ï¸ PentestGPT-Gemini initialized (GPT-4 free)")

    async def analyze_target(self, target_info: Dict[str, Any]) -> Dict[str, Any]:
        """Comprehensive target analysis using Gemini only"""
        logger.info(f"ðŸŽ¯ Analyzing target: {target_info.get('target', 'Unknown')}")
        
        try:
            # Create detailed analysis prompt
            analysis_prompt = f"""As an expert penetration tester, perform comprehensive target analysis:

TARGET INFORMATION:
{json.dumps(target_info, indent=2)}

Provide detailed analysis including:

1. **TARGET RECONNAISSANCE**:
   - Attack surface identification
   - Technology stack assessment
   - Potential entry points
   - Information gathering strategy

2. **VULNERABILITY ASSESSMENT**:
   - Common vulnerability patterns for this target type
   - High-priority testing areas
   - Known CVEs and security issues
   - Configuration weaknesses to investigate

3. **EXPLOITATION STRATEGY**:
   - Attack vector prioritization
   - Payload development approach
   - Privilege escalation opportunities
   - Persistence mechanisms

4. **TESTING METHODOLOGY**:
   - Phase-by-phase testing approach
   - Tool selection and configuration
   - Manual testing priorities
   - Automated testing integration

5. **RISK ASSESSMENT**:
   - Business impact evaluation
   - Technical risk scoring
   - Compliance considerations
   - Remediation priority matrix

Provide actionable, detailed guidance for ethical penetration testing."""
            
            # Generate analysis using Gemini
            response = await asyncio.to_thread(
                self.model.generate_content,
                analysis_prompt
            )
            
            # Structure the response
            analysis_result = {
                "target": target_info.get('target', 'Unknown'),
                "analysis_type": "comprehensive_target_analysis",
                "detailed_analysis": response.text,
                "generated_at": datetime.now().isoformat(),
                "model_used": self.model_name,
                "analysis_components": self._extract_analysis_components(response.text),
                "risk_level": self._assess_target_risk(target_info, response.text),
                "recommended_tools": self._extract_recommended_tools(response.text),
                "testing_phases": self._extract_testing_phases(response.text)
            }
            
            # Save analysis
            await self._save_analysis(analysis_result)
            
            logger.info(f"âœ… Target analysis completed for {target_info.get('target')}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ Target analysis failed: {e}")
            return {"error": str(e), "status": "failed"}

    async def perform_vulnerability_analysis(self, vulnerability_data: Dict[str, Any]) -> Dict[str, Any]:
        """Advanced vulnerability analysis using Gemini"""
        logger.info("ðŸ” Performing vulnerability analysis...")
        
        try:
            vuln_prompt = f"""Perform expert-level vulnerability analysis on this data:

VULNERABILITY DATA:
{json.dumps(vulnerability_data, indent=2)}

Provide comprehensive analysis including:

1. **VULNERABILITY CLASSIFICATION**:
   - CVE identification and mapping
   - OWASP Top 10 categorization
   - CWE classification
   - Severity assessment (CVSS 3.1)

2. **EXPLOITATION ANALYSIS**:
   - Exploitability assessment
   - Attack complexity evaluation
   - Required privileges analysis
   - User interaction requirements

3. **IMPACT ASSESSMENT**:
   - Confidentiality impact
   - Integrity impact
   - Availability impact
   - Business impact evaluation

4. **PROOF OF CONCEPT**:
   - Exploitation methodology
   - Payload development guidance
   - Testing procedures
   - Verification methods

5. **REMEDIATION STRATEGY**:
   - Immediate mitigation steps
   - Long-term fixes
   - Compensating controls
   - Validation procedures

6. **RELATED VULNERABILITIES**:
   - Chaining opportunities
   - Similar vulnerability patterns
   - Systemic issues identification
   - Defense evasion techniques

Provide detailed, actionable vulnerability intelligence."""
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                vuln_prompt
            )
            
            vuln_analysis = {
                "vulnerability_id": vulnerability_data.get('id', 'unknown'),
                "analysis_type": "detailed_vulnerability_analysis",
                "detailed_analysis": response.text,
                "generated_at": datetime.now().isoformat(),
                "severity_assessment": self._extract_severity(response.text),
                "exploitability_score": self._calculate_exploitability(response.text),
                "remediation_priority": self._determine_remediation_priority(response.text),
                "related_cves": self._extract_cves(response.text),
                "attack_vectors": self._extract_attack_vectors(response.text),
                "mitigation_strategies": self._extract_mitigations(response.text)
            }
            
            await self._save_analysis(vuln_analysis)
            
            logger.info("âœ… Vulnerability analysis completed")
            return vuln_analysis
            
        except Exception as e:
            logger.error(f"âŒ Vulnerability analysis failed: {e}")
            return {"error": str(e), "status": "failed"}

    async def generate_penetration_test_plan(self, scope: Dict[str, Any]) -> Dict[str, Any]:
        """Generate comprehensive penetration testing plan"""
        logger.info("ðŸ“‹ Generating penetration test plan...")
        
        try:
            plan_prompt = f"""Create a comprehensive penetration testing plan:

TESTING SCOPE:
{json.dumps(scope, indent=2)}

Generate detailed plan including:

1. **EXECUTIVE SUMMARY**:
   - Testing objectives
   - Scope definition
   - Key deliverables
   - Timeline overview

2. **METHODOLOGY**:
   - Testing framework (OWASP, NIST, PTES)
   - Phase breakdown
   - Testing approach (black/gray/white box)
   - Rules of engagement

3. **RECONNAISSANCE PHASE**:
   - Passive information gathering
   - Active reconnaissance
   - Social engineering assessment
   - OSINT procedures

4. **VULNERABILITY ASSESSMENT**:
   - Automated scanning procedures
   - Manual testing methodology
   - Custom payload development
   - Zero-day research approach

5. **EXPLOITATION PHASE**:
   - Exploitation methodology
   - Privilege escalation strategy
   - Lateral movement planning
   - Persistence mechanisms

6. **POST-EXPLOITATION**:
   - Data exfiltration simulation
   - Impact demonstration
   - Evidence collection
   - Clean-up procedures

7. **REPORTING**:
   - Report structure
   - Audience considerations
   - Remediation tracking
   - Follow-up procedures

8. **RESOURCE REQUIREMENTS**:
   - Team composition
   - Tool requirements
   - Infrastructure needs
   - Timeline estimates

Provide a professional, implementable penetration testing plan."""
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                plan_prompt
            )
            
            test_plan = {
                "plan_id": f"pentest_plan_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "scope": scope,
                "detailed_plan": response.text,
                "generated_at": datetime.now().isoformat(),
                "testing_phases": self._extract_testing_phases(response.text),
                "estimated_duration": self._extract_duration(response.text),
                "resource_requirements": self._extract_resources(response.text),
                "deliverables": self._extract_deliverables(response.text),
                "compliance_frameworks": self._extract_compliance(response.text)
            }
            
            # Save plan
            plan_file = self.analysis_dir / f"pentest_plan_{test_plan['plan_id']}.json"
            with open(plan_file, 'w', encoding='utf-8') as f:
                json.dump(test_plan, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… Penetration test plan generated: {plan_file}")
            return test_plan
            
        except Exception as e:
            logger.error(f"âŒ Test plan generation failed: {e}")
            return {"error": str(e), "status": "failed"}

    async def analyze_network_traffic(self, traffic_data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze network traffic for security issues"""
        logger.info("ðŸŒ Analyzing network traffic...")
        
        try:
            traffic_prompt = f"""Analyze this network traffic data for security issues:

TRAFFIC DATA:
{json.dumps(traffic_data, indent=2)}

Provide comprehensive analysis including:

1. **TRAFFIC PATTERN ANALYSIS**:
   - Normal vs anomalous behavior
   - Communication patterns
   - Protocol usage analysis
   - Bandwidth utilization

2. **SECURITY INDICATORS**:
   - Malicious IP identification
   - Suspicious port usage
   - Protocol anomalies
   - Payload analysis

3. **ATTACK DETECTION**:
   - Known attack signatures
   - Zero-day indicators
   - Command and control traffic
   - Data exfiltration patterns

4. **THREAT INTELLIGENCE**:
   - IOC correlation
   - Threat actor attribution
   - Campaign identification
   - TTPs mapping

5. **INCIDENT RESPONSE**:
   - Containment recommendations
   - Evidence preservation
   - Investigation priorities
   - Recovery procedures

6. **PREVENTION STRATEGIES**:
   - Network segmentation
   - Monitoring improvements
   - Rule development
   - Detection tuning

Provide actionable security intelligence from traffic analysis."""
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                traffic_prompt
            )
            
            traffic_analysis = {
                "analysis_id": f"traffic_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "traffic_summary": traffic_data,
                "detailed_analysis": response.text,
                "generated_at": datetime.now().isoformat(),
                "threat_indicators": self._extract_threat_indicators(response.text),
                "risk_score": self._calculate_risk_score(response.text),
                "recommended_actions": self._extract_actions(response.text),
                "iocs": self._extract_iocs(response.text)
            }
            
            await self._save_analysis(traffic_analysis)
            
            logger.info("âœ… Network traffic analysis completed")
            return traffic_analysis
            
        except Exception as e:
            logger.error(f"âŒ Traffic analysis failed: {e}")
            return {"error": str(e), "status": "failed"}
        
        if not self.model:
            logger.warning("âš ï¸ Gemini API not available for PentestGPT")
            
        logger.info("ðŸ§  PentestGPT initialized with shared Gemini client")

    def _initialize_ai_client(self):
        """Initialize the AI client (Gemini or Azure OpenAI)"""
        if self.gemini_api_key:
            genai.configure(api_key=self.gemini_api_key)
            self.client_type = "gemini"
            self.model = genai.GenerativeModel('gemini-pro')
            logger.info("Using Gemini API for PentestGPT")
        elif self.azure_openai_key:
            # Azure OpenAI client setup would go here
            self.client_type = "azure_openai"
            logger.info("Using Azure OpenAI for PentestGPT")
        else:
            raise ValueError("No AI API key provided! Set GEMINI_API_KEY or AZURE_OPENAI_API_KEY")

    async def analyze_security_scenario(self, query: str, context: Optional[str] = None) -> Dict[str, Any]:
        """
        Analyze a cybersecurity scenario using multi-step reasoning
        """
        logger.info(f"Starting security analysis for query: {query[:100]}...")
        
        try:
            # Step 1: Initial Analysis
            initial_analysis = await self._perform_initial_analysis(query, context)
            
            # Step 2: Deep Dive Analysis
            detailed_analysis = await self._perform_detailed_analysis(query, initial_analysis)
            
            # Step 3: Attack Vector Identification
            attack_vectors = await self._identify_attack_vectors(query, detailed_analysis)
            
            # Step 4: Mitigation Strategies
            mitigation_strategies = await self._generate_mitigation_strategies(query, attack_vectors)
            
            # Step 5: Risk Assessment
            risk_assessment = await self._assess_risk_level(query, attack_vectors)
            
            # Compile results
            result = {
                "query": query,
                "timestamp": datetime.now().isoformat(),
                "initial_analysis": initial_analysis,
                "detailed_analysis": detailed_analysis,
                "attack_vectors": attack_vectors,
                "mitigation_strategies": mitigation_strategies,
                "risk_assessment": risk_assessment,
                "reasoning_steps": 5
            }
            
            # Log the complete analysis
            await self._log_analysis(result)
            
            logger.info("Security analysis completed successfully")
            return result
            
        except Exception as e:
            logger.error(f"Analysis failed: {e}")
            raise

    async def _perform_initial_analysis(self, query: str, context: Optional[str] = None) -> str:
        """Step 1: Perform initial security analysis"""
        
        system_prompt = self.config['pentestgpt']['system_prompt']
        
        analysis_prompt = f"""
{system_prompt}

INITIAL RECONNAISSANCE ANALYSIS:

Query: {query}
{f"Additional Context: {context}" if context else ""}

Provide an initial security assessment covering:
1. Target surface analysis
2. Potential entry points
3. Common vulnerabilities for this scenario
4. Initial reconnaissance approach
5. Scope and limitations

Focus on practical, actionable insights. Be concise but thorough.
        """
        
        if self.model:
            response = await self._call_gemini(analysis_prompt)
        else:
            response = await self._call_azure_openai(analysis_prompt)
        
        return response

    async def _perform_detailed_analysis(self, query: str, initial_analysis: str) -> str:
        """Step 2: Perform detailed technical analysis"""
        
        detailed_prompt = f"""
Based on the initial analysis, provide a detailed technical breakdown:

Original Query: {query}
Initial Analysis: {initial_analysis}

DETAILED TECHNICAL ANALYSIS:

1. **Technical Deep Dive:**
   - Specific vulnerabilities and CVEs
   - Technical exploitation details
   - Tool recommendations and usage
   - Advanced techniques applicable

2. **Evidence Collection:**
   - What evidence to look for
   - How to document findings
   - Proof-of-concept development

3. **Exploitation Chain:**
   - Step-by-step exploitation methodology
   - Prerequisites and dependencies
   - Expected outcomes and artifacts

Provide technical depth while remaining educational and ethical.
        """
        
        if self.model:
            response = await self._call_gemini(detailed_prompt)
        else:
            response = await self._call_azure_openai(detailed_prompt)
        
        return response

    async def _identify_attack_vectors(self, query: str, analysis: str) -> str:
        """Step 3: Identify and prioritize attack vectors"""
        
        vectors_prompt = f"""
Based on the analysis, identify and prioritize attack vectors:

Query: {query}
Analysis: {analysis}

ATTACK VECTOR IDENTIFICATION:

1. **Primary Attack Vectors** (High probability):
   - Vector description
   - Likelihood of success
   - Required skills/tools
   - Detection probability

2. **Secondary Attack Vectors** (Medium probability):
   - Alternative approaches
   - Contingency methods
   - Social engineering aspects

3. **Advanced Attack Vectors** (Low probability, high impact):
   - Zero-day potential
   - Advanced persistent threat techniques
   - Supply chain attacks

Rank each vector by: Impact (1-10), Likelihood (1-10), Detection Risk (1-10)
        """
        
        if self.model:
            response = await self._call_gemini(vectors_prompt)
        else:
            response = await self._call_azure_openai(vectors_prompt)
        
        return response

    async def _generate_mitigation_strategies(self, query: str, attack_vectors: str) -> str:
        """Step 4: Generate comprehensive mitigation strategies"""
        
        mitigation_prompt = f"""
Develop comprehensive mitigation strategies:

Query: {query}
Identified Attack Vectors: {attack_vectors}

MITIGATION STRATEGY FRAMEWORK:

1. **Immediate Actions** (0-24 hours):
   - Emergency response steps
   - Immediate threat containment
   - Critical patch deployment

2. **Short-term Measures** (1-30 days):
   - Security hardening
   - Monitoring enhancement
   - Process improvements

3. **Long-term Strategy** (30+ days):
   - Architectural changes
   - Security program enhancements
   - Training and awareness

4. **Detection & Monitoring:**
   - What to monitor
   - Alert thresholds
   - Incident response procedures

Prioritize by effectiveness and implementation complexity.
        """
        
        if self.model:
            response = await self._call_gemini(mitigation_prompt)
        else:
            response = await self._call_azure_openai(mitigation_prompt)
        
        return response

    async def _assess_risk_level(self, query: str, attack_vectors: str) -> Dict[str, Any]:
        """Step 5: Assess overall risk level and impact"""
        
        risk_prompt = f"""
Provide a comprehensive risk assessment:

Query: {query}
Attack Vectors: {attack_vectors}

RISK ASSESSMENT MATRIX:

Evaluate and provide scores (1-10) for:
1. **Impact Severity**: Business, operational, financial, reputational
2. **Likelihood**: Probability of successful attack
3. **Detectability**: Ability to detect the attack
4. **Recovery Complexity**: Time and resources to recover

Return assessment in this JSON format:
{
  "overall_risk_score": 8.5,
  "impact_severity": 9,
  "likelihood": 7,
  "detectability": 6,
  "recovery_complexity": 8,
  "risk_category": "HIGH",
  "business_impact": "Description of business impact",
  "executive_summary": "Brief executive summary",
  "recommended_actions": ["Action 1", "Action 2", "Action 3"]
}
        """
        
        if self.client_type == "gemini":
            response = await self._call_gemini(risk_prompt)
        else:
            response = await self._call_azure_openai(risk_prompt)
        
        try:
            # Parse JSON response
            risk_data = json.loads(response)
            return risk_data
        except json.JSONDecodeError:
            # Fallback if JSON parsing fails
            return {
                "overall_risk_score": 7.0,
                "risk_category": "MEDIUM",
                "executive_summary": response[:200] + "...",
                "parsing_error": True
            }

    async def _call_gemini(self, prompt: str) -> str:
        """Call Gemini API directly using configured model"""
        try:
            if not self.model:
                raise ValueError("Gemini model not initialized")
            
            response = self.model.generate_content(prompt)
            return response.text if response and response.text else "No response generated"
        except Exception as e:
            logger.error(f"Gemini API call failed: {e}")
            raise

    async def _call_azure_openai(self, prompt: str) -> str:
        """Call Azure OpenAI API (placeholder)"""
        # Implementation for Azure OpenAI would go here
        logger.warning("Azure OpenAI not implemented yet")
        return "Azure OpenAI response placeholder"

    async def _log_analysis(self, result: Dict[str, Any]):
        """Log the complete analysis to file"""
        log_file = Path(f"logs/pentestgpt/analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        
        with open(log_file, 'w') as f:
            json.dump(result, f, indent=2, default=str)
        
        logger.info(f"Analysis logged to: {log_file}")

    async def generate_exploitation_guide(self, vulnerability: str, target_context: str) -> Dict[str, Any]:
        """Generate step-by-step exploitation guide"""
        
        guide_prompt = f"""
Generate a comprehensive exploitation guide for educational purposes:

Vulnerability: {vulnerability}
Target Context: {target_context}

EXPLOITATION GUIDE STRUCTURE:

1. **Vulnerability Overview:**
   - CVE information (if applicable)
   - Technical description
   - Affected systems/versions

2. **Prerequisites:**
   - Required tools and setup
   - Environmental conditions
   - Skill level required

3. **Exploitation Steps:**
   - Step-by-step methodology
   - Command examples (sanitized)
   - Expected outputs

4. **Post-Exploitation:**
   - Privilege escalation options
   - Persistence mechanisms
   - Data exfiltration methods

5. **Detection Evasion:**
   - Common detection methods
   - Evasion techniques
   - Anti-forensics considerations

6. **Educational Notes:**
   - Why this works
   - Common mistakes
   - Defensive perspectives

IMPORTANT: This is for educational and defensive purposes only.
        """
        
        try:
            if self.model:
                response = await self._call_gemini(guide_prompt)
            else:
                response = await self._call_azure_openai(guide_prompt)
            
            guide = {
                "vulnerability": vulnerability,
                "target_context": target_context,
                "guide_content": response,
                "timestamp": datetime.now().isoformat(),
                "educational_disclaimer": True
            }
            
            # Log the guide
            await self._log_analysis(guide)
            
            return guide
            
        except Exception as e:
            logger.error(f"Guide generation failed: {e}")
            raise

    async def analyze_incident_response(self, incident_description: str) -> Dict[str, Any]:
        """Analyze incident and provide response recommendations"""
        
        ir_prompt = f"""
Analyze this security incident and provide response recommendations:

Incident Description: {incident_description}

INCIDENT RESPONSE ANALYSIS:

1. **Incident Classification:**
   - Severity level (1-5)
   - Incident type
   - Affected systems/data

2. **Immediate Response:**
   - Containment actions
   - Evidence preservation
   - Communication requirements

3. **Investigation Steps:**
   - Forensic procedures
   - Log analysis approach
   - IOC identification

4. **Recovery Actions:**
   - System restoration
   - Security hardening
   - Monitoring enhancements

5. **Lessons Learned:**
   - Root cause analysis
   - Process improvements
   - Training recommendations

Provide actionable, prioritized recommendations.
        """
        
        try:
            if self.client_type == "gemini":
                response = await self._call_gemini(ir_prompt)
            else:
                response = await self._call_azure_openai(ir_prompt)
            
            analysis = {
                "incident_description": incident_description,
                "response_analysis": response,
                "timestamp": datetime.now().isoformat(),
                "analysis_type": "incident_response"
            }
            
            await self._log_analysis(analysis)
            return analysis
            
        except Exception as e:
            logger.error(f"Incident analysis failed: {e}")
            raise

if __name__ == "__main__":
    # Test the PentestGPT functionality
    async def test_pentestgpt():
        with open('config.yaml', 'r') as f:
            config = yaml.safe_load(f)
        
        pentestgpt = PentestGPT(config)
        
        # Test analysis
        result = await pentestgpt.analyze_security_scenario(
            "How to test for SQL injection in a login form with rate limiting?"
        )
        
        print("Analysis completed!")
        print(f"Risk Level: {result['risk_assessment'].get('risk_category', 'Unknown')}")
    
    # Uncomment to test
    # asyncio.run(test_pentestgpt())
