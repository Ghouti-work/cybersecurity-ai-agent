#!/usr/bin/env python3
"""
PentestGPT with Gemini API Integration
Advanced cybersecurity reasoning and analysis
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import os

import google.generativeai as genai
from loguru import logger
import yaml

from shared_utils import (
    ConfigManager, LoggerManager, GeminiClient, 
    DirectoryManager, PromptTemplates
)

class PentestGPT:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        
        # Setup logging using shared utility
        LoggerManager.setup_logger('pentestgpt')
        
        # Initialize shared Gemini client
        self.gemini_client = GeminiClient()
        
        if not self.gemini_client.is_available:
            logger.warning("âš ï¸ Gemini API not available for PentestGPT")
            
        logger.info("ðŸ§  PentestGPT initialized with shared Gemini client")

    def _initialize_ai_client(self):
        """Initialize the AI client (Gemini or Azure OpenAI)"""
        if self.gemini_api_key:
            genai.configure(api_key=self.gemini_api_key)
            self.client_type = "gemini"
            self.model = genai.GenerativeModel('gemini-pro')
            logger.info("Using Gemini API for PentestGPT")
        elif self.azure_openai_key:
            # Azure OpenAI client setup would go here
            self.client_type = "azure_openai"
            logger.info("Using Azure OpenAI for PentestGPT")
        else:
            raise ValueError("No AI API key provided! Set GEMINI_API_KEY or AZURE_OPENAI_API_KEY")

    async def analyze_security_scenario(self, query: str, context: Optional[str] = None) -> Dict[str, Any]:
        """
        Analyze a cybersecurity scenario using multi-step reasoning
        """
        logger.info(f"Starting security analysis for query: {query[:100]}...")
        
        try:
            # Step 1: Initial Analysis
            initial_analysis = await self._perform_initial_analysis(query, context)
            
            # Step 2: Deep Dive Analysis
            detailed_analysis = await self._perform_detailed_analysis(query, initial_analysis)
            
            # Step 3: Attack Vector Identification
            attack_vectors = await self._identify_attack_vectors(query, detailed_analysis)
            
            # Step 4: Mitigation Strategies
            mitigation_strategies = await self._generate_mitigation_strategies(query, attack_vectors)
            
            # Step 5: Risk Assessment
            risk_assessment = await self._assess_risk_level(query, attack_vectors)
            
            # Compile results
            result = {
                "query": query,
                "timestamp": datetime.now().isoformat(),
                "initial_analysis": initial_analysis,
                "detailed_analysis": detailed_analysis,
                "attack_vectors": attack_vectors,
                "mitigation_strategies": mitigation_strategies,
                "risk_assessment": risk_assessment,
                "reasoning_steps": 5
            }
            
            # Log the complete analysis
            await self._log_analysis(result)
            
            logger.info("Security analysis completed successfully")
            return result
            
        except Exception as e:
            logger.error(f"Analysis failed: {e}")
            raise

    async def _perform_initial_analysis(self, query: str, context: Optional[str] = None) -> str:
        """Step 1: Perform initial security analysis"""
        
        system_prompt = self.config['pentestgpt']['system_prompt']
        
        analysis_prompt = f"""
{system_prompt}

INITIAL RECONNAISSANCE ANALYSIS:

Query: {query}
{f"Additional Context: {context}" if context else ""}

Provide an initial security assessment covering:
1. Target surface analysis
2. Potential entry points
3. Common vulnerabilities for this scenario
4. Initial reconnaissance approach
5. Scope and limitations

Focus on practical, actionable insights. Be concise but thorough.
        """
        
        if self.gemini_client.is_available:
            response = await self._call_gemini(analysis_prompt)
        else:
            response = await self._call_azure_openai(analysis_prompt)
        
        return response

    async def _perform_detailed_analysis(self, query: str, initial_analysis: str) -> str:
        """Step 2: Perform detailed technical analysis"""
        
        detailed_prompt = f"""
Based on the initial analysis, provide a detailed technical breakdown:

Original Query: {query}
Initial Analysis: {initial_analysis}

DETAILED TECHNICAL ANALYSIS:

1. **Technical Deep Dive:**
   - Specific vulnerabilities and CVEs
   - Technical exploitation details
   - Tool recommendations and usage
   - Advanced techniques applicable

2. **Evidence Collection:**
   - What evidence to look for
   - How to document findings
   - Proof-of-concept development

3. **Exploitation Chain:**
   - Step-by-step exploitation methodology
   - Prerequisites and dependencies
   - Expected outcomes and artifacts

Provide technical depth while remaining educational and ethical.
        """
        
        if self.gemini_client.is_available:
            response = await self._call_gemini(detailed_prompt)
        else:
            response = await self._call_azure_openai(detailed_prompt)
        
        return response

    async def _identify_attack_vectors(self, query: str, analysis: str) -> str:
        """Step 3: Identify and prioritize attack vectors"""
        
        vectors_prompt = f"""
Based on the analysis, identify and prioritize attack vectors:

Query: {query}
Analysis: {analysis}

ATTACK VECTOR IDENTIFICATION:

1. **Primary Attack Vectors** (High probability):
   - Vector description
   - Likelihood of success
   - Required skills/tools
   - Detection probability

2. **Secondary Attack Vectors** (Medium probability):
   - Alternative approaches
   - Contingency methods
   - Social engineering aspects

3. **Advanced Attack Vectors** (Low probability, high impact):
   - Zero-day potential
   - Advanced persistent threat techniques
   - Supply chain attacks

Rank each vector by: Impact (1-10), Likelihood (1-10), Detection Risk (1-10)
        """
        
        if self.gemini_client.is_available:
            response = await self._call_gemini(vectors_prompt)
        else:
            response = await self._call_azure_openai(vectors_prompt)
        
        return response

    async def _generate_mitigation_strategies(self, query: str, attack_vectors: str) -> str:
        """Step 4: Generate comprehensive mitigation strategies"""
        
        mitigation_prompt = f"""
Develop comprehensive mitigation strategies:

Query: {query}
Identified Attack Vectors: {attack_vectors}

MITIGATION STRATEGY FRAMEWORK:

1. **Immediate Actions** (0-24 hours):
   - Emergency response steps
   - Immediate threat containment
   - Critical patch deployment

2. **Short-term Measures** (1-30 days):
   - Security hardening
   - Monitoring enhancement
   - Process improvements

3. **Long-term Strategy** (30+ days):
   - Architectural changes
   - Security program enhancements
   - Training and awareness

4. **Detection & Monitoring:**
   - What to monitor
   - Alert thresholds
   - Incident response procedures

Prioritize by effectiveness and implementation complexity.
        """
        
        if self.gemini_client.is_available:
            response = await self._call_gemini(mitigation_prompt)
        else:
            response = await self._call_azure_openai(mitigation_prompt)
        
        return response

    async def _assess_risk_level(self, query: str, attack_vectors: str) -> Dict[str, Any]:
        """Step 5: Assess overall risk level and impact"""
        
        risk_prompt = f"""
Provide a comprehensive risk assessment:

Query: {query}
Attack Vectors: {attack_vectors}

RISK ASSESSMENT MATRIX:

Evaluate and provide scores (1-10) for:
1. **Impact Severity**: Business, operational, financial, reputational
2. **Likelihood**: Probability of successful attack
3. **Detectability**: Ability to detect the attack
4. **Recovery Complexity**: Time and resources to recover

Return assessment in this JSON format:
{
  "overall_risk_score": 8.5,
  "impact_severity": 9,
  "likelihood": 7,
  "detectability": 6,
  "recovery_complexity": 8,
  "risk_category": "HIGH",
  "business_impact": "Description of business impact",
  "executive_summary": "Brief executive summary",
  "recommended_actions": ["Action 1", "Action 2", "Action 3"]
}
        """
        
        if self.client_type == "gemini":
            response = await self._call_gemini(risk_prompt)
        else:
            response = await self._call_azure_openai(risk_prompt)
        
        try:
            # Parse JSON response
            risk_data = json.loads(response)
            return risk_data
        except json.JSONDecodeError:
            # Fallback if JSON parsing fails
            return {
                "overall_risk_score": 7.0,
                "risk_category": "MEDIUM",
                "executive_summary": response[:200] + "...",
                "parsing_error": True
            }

    async def _call_gemini(self, prompt: str) -> str:
        """Call Gemini API using shared client"""
        try:
            return await self.gemini_client.generate_content(prompt)
        except Exception as e:
            logger.error(f"Gemini API call failed: {e}")
            raise

    async def _call_azure_openai(self, prompt: str) -> str:
        """Call Azure OpenAI API (placeholder)"""
        # Implementation for Azure OpenAI would go here
        logger.warning("Azure OpenAI not implemented yet")
        return "Azure OpenAI response placeholder"

    async def _log_analysis(self, result: Dict[str, Any]):
        """Log the complete analysis to file"""
        log_file = Path(f"logs/pentestgpt/analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        
        with open(log_file, 'w') as f:
            json.dump(result, f, indent=2, default=str)
        
        logger.info(f"Analysis logged to: {log_file}")

    async def generate_exploitation_guide(self, vulnerability: str, target_context: str) -> Dict[str, Any]:
        """Generate step-by-step exploitation guide"""
        
        guide_prompt = f"""
Generate a comprehensive exploitation guide for educational purposes:

Vulnerability: {vulnerability}
Target Context: {target_context}

EXPLOITATION GUIDE STRUCTURE:

1. **Vulnerability Overview:**
   - CVE information (if applicable)
   - Technical description
   - Affected systems/versions

2. **Prerequisites:**
   - Required tools and setup
   - Environmental conditions
   - Skill level required

3. **Exploitation Steps:**
   - Step-by-step methodology
   - Command examples (sanitized)
   - Expected outputs

4. **Post-Exploitation:**
   - Privilege escalation options
   - Persistence mechanisms
   - Data exfiltration methods

5. **Detection Evasion:**
   - Common detection methods
   - Evasion techniques
   - Anti-forensics considerations

6. **Educational Notes:**
   - Why this works
   - Common mistakes
   - Defensive perspectives

IMPORTANT: This is for educational and defensive purposes only.
        """
        
        try:
            if self.gemini_client.is_available:
                response = await self._call_gemini(guide_prompt)
            else:
                response = await self._call_azure_openai(guide_prompt)
            
            guide = {
                "vulnerability": vulnerability,
                "target_context": target_context,
                "guide_content": response,
                "timestamp": datetime.now().isoformat(),
                "educational_disclaimer": True
            }
            
            # Log the guide
            await self._log_analysis(guide)
            
            return guide
            
        except Exception as e:
            logger.error(f"Guide generation failed: {e}")
            raise

    async def analyze_incident_response(self, incident_description: str) -> Dict[str, Any]:
        """Analyze incident and provide response recommendations"""
        
        ir_prompt = f"""
Analyze this security incident and provide response recommendations:

Incident Description: {incident_description}

INCIDENT RESPONSE ANALYSIS:

1. **Incident Classification:**
   - Severity level (1-5)
   - Incident type
   - Affected systems/data

2. **Immediate Response:**
   - Containment actions
   - Evidence preservation
   - Communication requirements

3. **Investigation Steps:**
   - Forensic procedures
   - Log analysis approach
   - IOC identification

4. **Recovery Actions:**
   - System restoration
   - Security hardening
   - Monitoring enhancements

5. **Lessons Learned:**
   - Root cause analysis
   - Process improvements
   - Training recommendations

Provide actionable, prioritized recommendations.
        """
        
        try:
            if self.client_type == "gemini":
                response = await self._call_gemini(ir_prompt)
            else:
                response = await self._call_azure_openai(ir_prompt)
            
            analysis = {
                "incident_description": incident_description,
                "response_analysis": response,
                "timestamp": datetime.now().isoformat(),
                "analysis_type": "incident_response"
            }
            
            await self._log_analysis(analysis)
            return analysis
            
        except Exception as e:
            logger.error(f"Incident analysis failed: {e}")
            raise

if __name__ == "__main__":
    # Test the PentestGPT functionality
    async def test_pentestgpt():
        with open('config.yaml', 'r') as f:
            config = yaml.safe_load(f)
        
        pentestgpt = PentestGPT(config)
        
        # Test analysis
        result = await pentestgpt.analyze_security_scenario(
            "How to test for SQL injection in a login form with rate limiting?"
        )
        
        print("Analysis completed!")
        print(f"Risk Level: {result['risk_assessment'].get('risk_category', 'Unknown')}")
    
    # Uncomment to test
    # asyncio.run(test_pentestgpt())
